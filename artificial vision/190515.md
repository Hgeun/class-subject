## encoder
- input data를 어떤 distribution 형태로 바꾸는(압축하는) 역할

## decoder
- distribution(code)을 이용해서 압축을 풀어주는 역할

## variational Autoencoder
- distribution을 가우시안으로 설정  
- 중간에 나오는 code가 평균과 편차(분산)이 나오도록  
  
## VAE vs GAN

x-(encoder)-> z -(deocoder or generator)-> ~x  
[~x, x] -(discriminator or classfier)-> real or fake  
<img src="https://cdn-images-1.medium.com/max/1600/0*KEmfTtghsCDu6UTb.png"  width="50%" height="50%">  
<img src="https://cdn-images-1.medium.com/max/1600/0*fEvjrIl9ar9fj51J.png"  width="50%" height="50%">  
  
  
## transposed convolution
<img src="https://cdn-images-1.medium.com/max/1200/1*NoXQbZqPnxSnjdAwo93XcQ.png"  width="50%" height="50%">  
<img src="https://cdn-images-1.medium.com/max/1600/1*ql2ZxrS_h8D7KHNCrGndug.png"  width="50%" height="50%">  
- 정확히 아래의 값들은 아니지만 이런 식으로 만드는 것  
- upsampling 시 사용  
<img src="https://user-images.githubusercontent.com/33209778/57746588-cdf1ce80-770c-11e9-8128-2bb84229f667.png"  width="50%" height="50%">  
- 하지만 이걸 사용하면 checkerboard artifact가 발생함  
- 차라리 bilinear interpolation같은거 써서 늘리고 convolution 하자,
<img src="https://user-images.githubusercontent.com/33209778/57746995-984de500-770e-11e9-9327-4918c0aef815.png"  width="50%" height="50%">
  
관련 글:  
[Deconvolution and Checkerboard Artifacts](https://distill.pub/2016/deconv-checkerboard)  
